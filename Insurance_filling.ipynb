{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b5AvqNXesph5",
        "outputId": "0f6e2cf9-8849-4189-df35-12d63b82ffa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "--2025-06-25 06:41:01--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64 [following]\n",
            "--2025-06-25 06:41:01--  https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/015db4d3-519c-4e00-a1a6-289640709684?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250625T064101Z&X-Amz-Expires=1800&X-Amz-Signature=2df46e151746ed0b9ffeea1fde1bb6d2c332d45d8d887d4eeea05101f1c9931a&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-06-25 06:41:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/015db4d3-519c-4e00-a1a6-289640709684?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250625T064101Z&X-Amz-Expires=1800&X-Amz-Signature=2df46e151746ed0b9ffeea1fde1bb6d2c332d45d8d887d4eeea05101f1c9931a&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41164185 (39M) [application/octet-stream]\n",
            "Saving to: â€˜cloudflaredâ€™\n",
            "\n",
            "cloudflared         100%[===================>]  39.26M   135MB/s    in 0.3s    \n",
            "\n",
            "2025-06-25 06:41:02 (135 MB/s) - â€˜cloudflaredâ€™ saved [41164185/41164185]\n",
            "\n",
            "Upload DOCX template file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-59afce88-d8d3-4fe7-81b6-9ac29435ddec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-59afce88-d8d3-4fe7-81b6-9ac29435ddec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Eberl-GuideOne REPORT TEMPLATE_XM8.docx to Eberl-GuideOne REPORT TEMPLATE_XM8.docx\n",
            "Upload PDF photo report:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e4a8a6f-245d-4722-9f1f-3815edc01daf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3e4a8a6f-245d-4722-9f1f-3815edc01daf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Photo Report - 3.pdf to Photo Report - 3.pdf\n",
            "Files uploaded successfully!\n",
            "Streamlit server starting... (wait 15 seconds)\n",
            "Cloudflare Tunnel starting... (wait 20 seconds)\n",
            "Public URL not found in logs. Here's the log content:\n",
            "2025-06-25T06:42:42Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "2025-06-25T06:42:42Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "2025-06-25T06:42:46Z INF +--------------------------------------------------------------------------------------------+\n",
            "2025-06-25T06:42:46Z INF |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "2025-06-25T06:42:46Z INF |  https://ware-philips-leaving-dpi.trycloudflare.com                                        |\n",
            "2025-06-25T06:42:46Z INF +--------------------------------------------------------------------------------------------+\n",
            "2025-06-25T06:42:46Z INF Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "2025-06-25T06:42:46Z INF Version 2025.6.1 (Checksum 103ff020ffcc4ad6b542948b95ecff417150c70a17bff3a39ac2670b4159c9bb)\n",
            "2025-06-25T06:42:46Z INF GOOS: linux, GOVersion: go1.24.2, GoArch: amd64\n",
            "2025-06-25T06:42:46Z INF Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "2025-06-25T06:42:46Z INF Autoupdate frequency is set autoupdateFreq=86400000\n",
            "2025-06-25T06:42:46Z INF Generated Connector ID: 3a532650-c226-447f-9b80-3bbd9a6703b6\n",
            "2025-06-25T06:42:46Z INF Initial protocol quic\n",
            "2025-06-25T06:42:46Z INF ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "2025-06-25T06:42:46Z INF ICMP proxy will use :: as source for IPv6\n",
            "2025-06-25T06:42:46Z INF ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "2025-06-25T06:42:46Z INF ICMP proxy will use :: as source for IPv6\n",
            "2025-06-25T06:42:46Z INF Starting metrics server on 127.0.0.1:20243/metrics\n",
            "2025-06-25T06:42:46Z INF Tunnel connection curve preferences: [X25519MLKEM768 CurveID(25497) CurveP256] connIndex=0 event=0 ip=198.41.192.7\n",
            "2025/06/25 06:42:46 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "2025-06-25T06:42:46Z INF Registered tunnel connection connIndex=0 connection=2498ea7d-4405-4132-b437-798f71fadcd8 event=0 ip=198.41.192.7 location=ord14 protocol=quic\n",
            "\n",
            "\n",
            "================================================================================\n",
            "IMPORTANT: Keep this Colab tab open to maintain the connection\n",
            "The application will be accessible as long as this session is active\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit openai PyMuPDF pdfplumber pytesseract pillow python-docx\n",
        "!sudo apt install -q tesseract-ocr libtesseract-dev\n",
        "\n",
        "# Install Cloudflare Tunnel\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n",
        "!mv cloudflared /usr/local/bin/\n",
        "\n",
        "# Step 2: Create application files with guaranteed filling\n",
        "import os\n",
        "\n",
        "# Create app.py\n",
        "app_py_content = \"\"\"\n",
        "import streamlit as st\n",
        "import os\n",
        "import tempfile\n",
        "from modules import extract_text_from_pdf, extract_kv_pairs, fill_template\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Insurance Document Automation\",\n",
        "    page_icon=\"ðŸ“‘\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.title(\"ðŸ“‘ USAA Insurance Document Automation\")\n",
        "st.caption(\"Upload DOCX template and PDF photo reports to generate filled insurance documents\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Configuration\")\n",
        "    api_key = st.text_input(\"OpenRouter API Key\", type=\"password\")\n",
        "    st.info(\"Get API key from [OpenRouter](https://openrouter.ai/keys)\")\n",
        "\n",
        "    # Model selection\n",
        "    model_options = {\n",
        "        \"Claude Haiku (Fast)\": \"anthropic/claude-3-haiku\",\n",
        "        \"DeepSeek Chat\": \"deepseek-chat\",\n",
        "        \"Google Gemini Pro\": \"google/gemini-pro\",\n",
        "        \"Mistral 7B\": \"mistralai/mistral-7b-instruct\"\n",
        "    }\n",
        "    selected_model = st.selectbox(\"Select AI Model\", list(model_options.keys()), index=0)\n",
        "    st.info(f\"Using model: {model_options[selected_model]}\")\n",
        "\n",
        "# File upload section\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    template_file = st.file_uploader(\"Upload DOCX Template\", type=[\"docx\"])\n",
        "\n",
        "with col2:\n",
        "    pdf_files = st.file_uploader(\"Upload PDF Photo Reports\",\n",
        "                                type=[\"pdf\"],\n",
        "                                accept_multiple_files=True)\n",
        "\n",
        "process_btn = st.button(\"Generate Document\", type=\"primary\", disabled=not (template_file and pdf_files))\n",
        "\n",
        "if process_btn:\n",
        "    if not api_key:\n",
        "        st.error(\"Please enter your OpenRouter API key\")\n",
        "        st.stop()\n",
        "\n",
        "    with st.status(\"Processing documents...\", expanded=True) as status:\n",
        "        # Save uploaded files temporarily\n",
        "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "            # Save template\n",
        "            template_path = os.path.join(tmp_dir, \"template.docx\")\n",
        "            with open(template_path, \"wb\") as f:\n",
        "                f.write(template_file.getvalue())\n",
        "\n",
        "            # Process PDFs\n",
        "            combined_text = \"\"\n",
        "            for pdf_file in pdf_files:\n",
        "                pdf_path = os.path.join(tmp_dir, pdf_file.name)\n",
        "                with open(pdf_path, \"wb\") as f:\n",
        "                    f.write(pdf_file.getbuffer())\n",
        "\n",
        "                st.write(f\"Processing {pdf_file.name}...\")\n",
        "                combined_text += extract_text_from_pdf(pdf_path) + \"\\\\n\\\\n\"\n",
        "\n",
        "            # Display extracted text\n",
        "            with st.expander(\"View extracted text\"):\n",
        "                st.text(combined_text[:5000] + \"...\" if len(combined_text) > 5000 else combined_text)\n",
        "\n",
        "            # Extract key-value pairs\n",
        "            st.write(\"Analyzing content with AI...\")\n",
        "            try:\n",
        "                context_data = extract_kv_pairs(combined_text, api_key, model_options[selected_model])\n",
        "                st.json(context_data)\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error during AI processing: {str(e)}\")\n",
        "                st.stop()\n",
        "\n",
        "            # Fill template\n",
        "            st.write(\"Generating final document...\")\n",
        "            try:\n",
        "                output_docx = fill_template(template_path, context_data)\n",
        "                status.update(label=\"Processing complete!\", state=\"complete\", expanded=False)\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error filling template: {str(e)}\")\n",
        "                st.stop()\n",
        "\n",
        "    # Download button\n",
        "    st.download_button(\n",
        "        label=\"Download Filled Document\",\n",
        "        data=output_docx,\n",
        "        file_name=\"filled_insurance_report.docx\",\n",
        "        mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
        "    )\n",
        "\n",
        "    # Show success message\n",
        "    st.success(\"Document generated successfully! Click the download button above.\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_py_content)\n",
        "\n",
        "# Create modules.py with guaranteed filling using direct XML manipulation\n",
        "modules_py_content = \"\"\"\n",
        "import fitz  # PyMuPDF\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "import json\n",
        "import re\n",
        "import openai\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "import sys\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \\\"\\\"\\\"Extract text from PDF with OCR fallback\\\"\\\"\\\"\n",
        "    full_text = \"\"\n",
        "\n",
        "    # First try with PyMuPDF for text-based PDFs\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        for page in doc:\n",
        "            text = page.get_text()\n",
        "            if text and len(text.strip()) > 50:  # Valid text page\n",
        "                full_text += text + \"\\\\n\\\\n\"\n",
        "            else:  # Likely image-based page\n",
        "                pix = page.get_pixmap()\n",
        "                img = Image.open(io.BytesIO(pix.tobytes()))\n",
        "                text = pytesseract.image_to_string(img)\n",
        "                full_text += text + \"\\\\n\\\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"PyMuPDF error: {e}, falling back to pdfplumber\")\n",
        "        # Fallback to pdfplumber\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    full_text += text + \"\\\\n\\\\n\"\n",
        "\n",
        "    return full_text\n",
        "\n",
        "def extract_kv_pairs(text, api_key, model_id):\n",
        "    \\\"\\\"\\\"Extract structured data using LLM with model fallback\\\"\\\"\\\"\n",
        "    client = openai.OpenAI(\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        api_key=api_key\n",
        "    )\n",
        "\n",
        "    # Create a more robust prompt with examples\n",
        "    prompt = f\\\"\\\"\\\"\n",
        "    Extract insurance claim information from the following report text.\n",
        "    Return ONLY valid JSON with no additional commentary. Use these exact keys:\n",
        "    - claim_number\n",
        "    - insured_name\n",
        "    - address_of_loss\n",
        "    - date_of_loss\n",
        "    - policy_number\n",
        "    - damage_description\n",
        "    - roof_damage_details\n",
        "    - fence_damage\n",
        "    - pool_damage\n",
        "    - food_loss_amount\n",
        "    - mortgage_company\n",
        "\n",
        "    Example Output:\n",
        "    {{\n",
        "      \"claim_number\": \"CL123456\",\n",
        "      \"insured_name\": \"John Doe\",\n",
        "      \"address_of_loss\": \"123 Main St, Anytown, ST 12345\",\n",
        "      \"date_of_loss\": \"2023-08-15\",\n",
        "      \"policy_number\": \"POL987654\",\n",
        "      \"damage_description\": \"Wind damage to roof and fence\",\n",
        "      \"roof_damage_details\": \"Multiple missing shingles on southwest section\",\n",
        "      \"fence_damage\": \"3 sections destroyed\",\n",
        "      \"pool_damage\": \"None\",\n",
        "      \"food_loss_amount\": \"250\",\n",
        "      \"mortgage_company\": \"ABC Mortgage\"\n",
        "    }}\n",
        "\n",
        "    Report Text:\n",
        "    {text[:12000]}  # Truncate to token limit\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "    # Try the requested model first\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_id,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=2000,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        json_str = response.choices[0].message.content\n",
        "        return json.loads(json_str)\n",
        "    except Exception as e:\n",
        "        # Fallback to Claude Haiku if the requested model fails\n",
        "        try:\n",
        "            print(f\"Model {model_id} failed, falling back to anthropic/claude-3-haiku\")\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"anthropic/claude-3-haiku\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=2000,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "            json_str = response.choices[0].message.content\n",
        "            return json.loads(json_str)\n",
        "        except Exception as fallback_e:\n",
        "            # Final fallback to regex extraction\n",
        "            error_msg = f\"Primary model error: {str(e)}\\\\nFallback model error: {str(fallback_e)}\"\n",
        "            print(error_msg)\n",
        "            return extract_kv_fallback(text)\n",
        "\n",
        "def extract_kv_fallback(text):\n",
        "    \\\"\\\"\\\"Fallback extraction for when LLM fails\\\"\\\"\\\"\n",
        "    print(\"Using regex fallback extraction\")\n",
        "    data = {}\n",
        "\n",
        "    # More robust regex patterns\n",
        "    patterns = {\n",
        "        \"claim_number\": r\"(?:Claim\\\\s*[#:]?|CL\\\\s*)\\\\s*([A-Z0-9-]+)\",\n",
        "        \"policy_number\": r\"(?:Policy\\\\s*[#:]?|POL\\\\s*)\\\\s*([A-Z0-9-]+)\",\n",
        "        \"insured_name\": r\"Insured:\\\\s*(.+?)(?=\\\\n|Address)\",\n",
        "        \"date_of_loss\": r\"Date\\\\s*of\\\\s*Loss:\\\\s*(\\\\d{1,2}[/-]\\\\d{1,2}[/-]\\\\d{4})\",\n",
        "        \"address_of_loss\": r\"Address\\\\s*of\\\\s*Loss:\\\\s*(.+?)(?=\\\\n|Date)\",\n",
        "        \"damage_description\": r\"Damage\\\\s*Description:\\\\s*(.+?)(?=\\\\n|Roof)\",\n",
        "        \"roof_damage_details\": r\"roof(?:.*?damage)?[.:]\\\\s*(.+?)(?=\\\\n|Fence)\",\n",
        "        \"fence_damage\": r\"fence(?:.*?damage)?[.:]\\\\s*(.+?)(?=\\\\n|Pool)\",\n",
        "        \"pool_damage\": r\"pool(?:.*?damage)?[.:]\\\\s*(.+?)(?=\\\\n|Food)\",\n",
        "        \"food_loss_amount\": r\"food\\\\s*loss\\\\s*amount\\\\D*(\\\\d+)\",\n",
        "        \"mortgage_company\": r\"mortgage\\\\s*company[\\\\s\\\\S]*?([A-Za-z0-9\\\\s&]+)\"\n",
        "    }\n",
        "\n",
        "    for key, pattern in patterns.items():\n",
        "        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "        if match:\n",
        "            data[key] = match.group(1).strip()\n",
        "        else:\n",
        "            # Search for key in text if pattern fails\n",
        "            if key in text:\n",
        "                start = text.find(key) + len(key)\n",
        "                end = text.find(\"\\\\n\", start)\n",
        "                data[key] = text[start:end].strip(\": \")[:100]\n",
        "            else:\n",
        "                data[key] = \"Not found\"\n",
        "\n",
        "    return data\n",
        "\n",
        "def fill_template(template_path, context_data):\n",
        "    \\\"\\\"\\\"Populate DOCX template with extracted data using direct XML replacement\\\"\\\"\\\"\n",
        "    # Set default values for missing fields\n",
        "    defaults = {\n",
        "        \"claim_number\": \"Unknown\",\n",
        "        \"insured_name\": \"Unknown\",\n",
        "        \"address_of_loss\": \"Unknown\",\n",
        "        \"date_of_loss\": \"Unknown\",\n",
        "        \"policy_number\": \"Unknown\",\n",
        "        \"damage_description\": \"No description provided\",\n",
        "        \"roof_damage_details\": \"No roof damage details\",\n",
        "        \"fence_damage\": \"No fence damage\",\n",
        "        \"pool_damage\": \"No pool damage\",\n",
        "        \"food_loss_amount\": \"0\",\n",
        "        \"mortgage_company\": \"Unknown\"\n",
        "    }\n",
        "\n",
        "    # Merge context with defaults\n",
        "    merged_context = {**defaults, **context_data}\n",
        "\n",
        "    # Create a temporary working directory\n",
        "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "        # Copy template to temporary directory\n",
        "        temp_docx = os.path.join(tmp_dir, \"template.docx\")\n",
        "        shutil.copyfile(template_path, temp_docx)\n",
        "\n",
        "        # Unzip the DOCX file\n",
        "        docx_dir = os.path.join(tmp_dir, \"docx_contents\")\n",
        "        with zipfile.ZipFile(temp_docx, 'r') as zip_ref:\n",
        "            zip_ref.extractall(docx_dir)\n",
        "\n",
        "        # Process document.xml\n",
        "        document_xml = os.path.join(docx_dir, \"word\", \"document.xml\")\n",
        "        if not os.path.exists(document_xml):\n",
        "            # Try alternative location\n",
        "            document_xml = os.path.join(docx_dir, \"document.xml\")\n",
        "            if not os.path.exists(document_xml):\n",
        "                raise FileNotFoundError(\"document.xml not found in DOCX file\")\n",
        "\n",
        "        # Read and process the XML\n",
        "        with open(document_xml, \"r\", encoding=\"utf-8\") as f:\n",
        "            xml_content = f.read()\n",
        "\n",
        "        # Replace placeholders in the XML content\n",
        "        for key, value in merged_context.items():\n",
        "            # Create all possible placeholder variations\n",
        "            patterns = [\n",
        "                f\"{{{{{key}}}}}\",       # {{key}}\n",
        "                f\"{{{{ {key} }}}}\",     # {{ key }}\n",
        "                f\"{{{{{key} }}}}\",      # {{key }}\n",
        "                f\"{{{{ {key}}}}}\",      # {{ key}}\n",
        "            ]\n",
        "\n",
        "            for pattern in patterns:\n",
        "                xml_content = xml_content.replace(pattern, str(value))\n",
        "\n",
        "        # Write back the modified XML\n",
        "        with open(document_xml, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(xml_content)\n",
        "\n",
        "        # Re-zip the document\n",
        "        filled_docx = os.path.join(tmp_dir, \"filled.docx\")\n",
        "        with zipfile.ZipFile(filled_docx, 'w') as zipf:\n",
        "            for root, _, files in os.walk(docx_dir):\n",
        "                for file in files:\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    arcname = os.path.relpath(file_path, docx_dir)\n",
        "                    zipf.write(file_path, arcname)\n",
        "\n",
        "        # Read the filled document into memory\n",
        "        with open(filled_docx, \"rb\") as f:\n",
        "            output_bytes = f.read()\n",
        "\n",
        "    # Return as BytesIO object\n",
        "    return io.BytesIO(output_bytes)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"modules.py\", \"w\") as f:\n",
        "    f.write(modules_py_content)\n",
        "\n",
        "# Step 3: Upload your sample files\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(\"templates\", exist_ok=True)\n",
        "os.makedirs(\"photo_reports\", exist_ok=True)\n",
        "\n",
        "# Upload template\n",
        "print(\"Upload DOCX template file:\")\n",
        "uploaded_template = files.upload()\n",
        "template_filename = list(uploaded_template.keys())[0]\n",
        "shutil.move(template_filename, f\"templates/{template_filename}\")\n",
        "\n",
        "# Upload photo report\n",
        "print(\"Upload PDF photo report:\")\n",
        "uploaded_report = files.upload()\n",
        "report_filename = list(uploaded_report.keys())[0]\n",
        "shutil.move(report_filename, f\"photo_reports/{report_filename}\")\n",
        "\n",
        "print(\"Files uploaded successfully!\")\n",
        "\n",
        "# Step 4: Run Streamlit with Cloudflare Tunnel\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Start Streamlit in background\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"])\n",
        "\n",
        "streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "streamlit_thread.start()\n",
        "print(\"Streamlit server starting... (wait 15 seconds)\")\n",
        "time.sleep(15)\n",
        "\n",
        "# Start Cloudflare Tunnel\n",
        "def run_cloudflared():\n",
        "    subprocess.run([\"/usr/local/bin/cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8501\"],\n",
        "                   stdout=open('tunnel.log', 'w'),\n",
        "                   stderr=subprocess.STDOUT)\n",
        "\n",
        "tunnel_thread = threading.Thread(target=run_cloudflared, daemon=True)\n",
        "tunnel_thread.start()\n",
        "print(\"Cloudflare Tunnel starting... (wait 20 seconds)\")\n",
        "time.sleep(20)\n",
        "\n",
        "# Extract the public URL\n",
        "try:\n",
        "    time.sleep(5)\n",
        "    with open('tunnel.log', 'r') as f:\n",
        "        log_content = f.read()\n",
        "\n",
        "    # Find URL in logs\n",
        "    import re\n",
        "    url_match = re.search(r'https://[a-z0-9-]+\\\\.trycloudflare\\\\.com', log_content)\n",
        "    if url_match:\n",
        "        public_url = url_match.group(0)\n",
        "        display(Markdown(f\"### [ACCESS YOUR STREAMLIT APP HERE]({public_url})\"))\n",
        "        print(f\"Public URL: {public_url}\")\n",
        "    else:\n",
        "        print(\"Public URL not found in logs. Here's the log content:\")\n",
        "        print(log_content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error getting URL: {str(e)}\")\n",
        "\n",
        "# Keep the session alive\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"IMPORTANT: Keep this Colab tab open to maintain the connection\")\n",
        "print(\"The application will be accessible as long as this session is active\")\n",
        "print(\"=\"*80)"
      ]
    }
  ]
}